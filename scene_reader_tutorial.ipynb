{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9856dcd8-2fb1-4b1b-8de4-5d6691a946b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Imports and Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acc5a97-e32c-4540-b9e8-425981efcb15",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0e1014-15cf-4179-8218-d2e5605e1a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rp\n",
    "import torch\n",
    "import einops\n",
    "import numpy\n",
    "\n",
    "from source.scene_reader import extract_seg_photo_rgb_and_labels, extract_scene_uvs_and_scene_labels\n",
    "from source.projector import colorized_scene_labels\n",
    "from source.unprojector import get_label_averge_colors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aabaffc-4e07-4a0b-950e-18b9502f11e5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcc0bfd-3ac9-4d0c-8db1-db10bbe64670",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Make the pixels of Jupyter-displayed images \n",
    "# use nearest-neigbor interpolation\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    "img {\n",
    "  image-rendering: auto;\n",
    "  image-rendering: crisp-edges;\n",
    "  image-rendering: pixelated;\n",
    "}\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc937b39-d1d8-43d7-bbee-4b1933146bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_colors(colors):\n",
    "    #Assumes 0<colors<1\n",
    "    import numpy as np\n",
    "    tiles = []\n",
    "    for index,color in enumerate(colors):\n",
    "        color = rp.as_numpy_array(color)\n",
    "        tile = np.ones((128,128,3))\n",
    "        tile = tile * color[None,None]\n",
    "        tiles.append(tile)\n",
    "    rp.display_image(rp.tiled_images(tiles))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff9b84b-0377-4b2b-94ce-c82177fea32f",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d3efcb-d0c0-4f17-aa48-c050569226bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_folder = 'datasets/five_items/photos_seg'\n",
    "assert rp.folder_exists(seg_folder)\n",
    "\n",
    "uvl_scene_folder = 'datasets/five_items/scenes'\n",
    "assert rp.folder_exists(uvl_scene_folder)\n",
    "\n",
    "label_values = [0,50,100,150,200,255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5996191-d037-43a2-a7e4-5f20316ae091",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_images = rp.load_images(seg_folder, use_cache=True, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136a16b9-9710-4116-8f94-5da18746e8be",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Seg Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336519d2-ed02-4594-8013-8a654f59c899",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_image = rp.random_element(seg_images)\n",
    "alpha = seg_image[:,:,3]\n",
    "\n",
    "rp.display_image(\n",
    "    rp.horizontally_concatenated_images(\n",
    "        seg_image,\n",
    "        alpha,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560e80e2-995b-4bcf-8aca-bf3dab85fe4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_images = [rp.as_float_image(x) for x in seg_images]\n",
    "torch_seg_images = rp.as_torch_images(rp.as_numpy_array(seg_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096caee9-6fa9-4184-88da-73d4a7d66f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb, labels = extract_seg_photo_rgb_and_labels(torch_seg_images, label_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da18b02-572a-4b6d-9c23-309daa92a64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random colors we use to visualize the labels\n",
    "\n",
    "colors = [\n",
    "    [0.5 , 0   , 0.5 ] ,\n",
    "    [0.5 , 1   , 0   ] ,\n",
    "    [0   , 0.5 , 0   ] ,\n",
    "    [0.5 , 0.5 , 0   ] ,\n",
    "    [0   , 1   , 1   ] ,\n",
    "    [0   , 0   , 1   ] ,\n",
    "    [0   , 0.5 , 0.5 ] ,\n",
    "    [0.5 , 1   , 0.5 ] ,\n",
    "    [0   , 0   , 0   ] ,\n",
    "    [0.5 , 0   , 0   ] ,\n",
    "    [1   , 0   , 0.5 ] ,\n",
    "    [0   , 0.5 , 1   ] ,\n",
    "    [1   , 0.5 , 0   ] ,\n",
    "    [1   , 1   , 1   ] ,\n",
    "    [0   , 1   , 0   ] ,\n",
    "    [0.5 , 0.5 , 0.5 ] ,\n",
    "    [0.5 , 0.5 , 1   ] ,\n",
    "    [1   , 1   , 0   ] ,\n",
    "    [0.5 , 1   , 1   ] ,\n",
    "    [0   , 0   , 0.5 ] ,\n",
    "    [1   , 0   , 0   ] ,\n",
    "    [0   , 1   , 0.5 ] ,\n",
    "    [0.5 , 0   , 1   ] ,\n",
    "    [1   , 0.5 , 1   ] ,\n",
    "    [1   , 0   , 1   ] ,\n",
    "    [1   , 1   , 0.5 ] ,\n",
    "    [1   , 0.5 , 0.5 ] ,\n",
    "]\n",
    "\n",
    "colors = torch.tensor(rp.as_numpy_array(colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92c18fc-bb6a-4c83-b55d-538960ca5e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "uvl_scenes = rp.get_all_files(uvl_scene_folder)\n",
    "uvl_scenes = rp.random_batch(uvl_scenes, 5)\n",
    "uvl_scenes = rp.load_images (uvl_scenes   )\n",
    "uvl_scenes = [rp.as_rgb_image  (x) for x in uvl_scenes]\n",
    "uvl_scenes = [rp.as_float_image(x) for x in uvl_scenes]\n",
    "uvl_scenes = rp.as_numpy_array (uvl_scenes)\n",
    "uvl_scenes = rp.as_torch_images(uvl_scenes)\n",
    "\n",
    "_, uvl_labels = extract_scene_uvs_and_scene_labels(uvl_scenes, label_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7572cb-963b-4145-8f30-d2a2b289b96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = rp.random_index(5)\n",
    "\n",
    "print(\"Make sure all the labels in the photo match all the labels in the UVL scene!\")\n",
    "print(\"Its a good oppurtunity to double-check your annotations\")\n",
    "\n",
    "rp.display_image(\n",
    "    rp.vertically_concatenated_images(\n",
    "        rp.horizontally_concatenated_images(\n",
    "            rp.labeled_image(\n",
    "                rp.as_numpy_image(uvl_scenes[index]),\n",
    "                'Synthetic UVL Scene',\n",
    "                size=30,\n",
    "            ),\n",
    "            rp.labeled_image(\n",
    "                rp.as_numpy_image(colorized_scene_labels(uvl_labels,colors)[index]),\n",
    "                'Synthetic UVL Labels',\n",
    "                size=30,\n",
    "            ),\n",
    "        ),\n",
    "        rp.horizontally_concatenated_images(\n",
    "            rp.labeled_image(\n",
    "                rp.as_numpy_image(rgb[index]),\n",
    "                'Photo',\n",
    "                size=30,\n",
    "            ),\n",
    "            rp.labeled_image(\n",
    "                rp.as_numpy_image(colorized_scene_labels(labels,colors)[index]),\n",
    "                'Photo Labels',\n",
    "                size=30,\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf40d7a-ed02-466c-a449-50490e884383",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Average Colors Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88724cb1-b01f-4bdf-b833-09d6fb71ae3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = get_label_averge_colors(rgb, labels, len(label_values))\n",
    "display_colors(colors)\n",
    "print(rp.as_numpy_array(colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6d0c85-d739-4597-9175-e79e02c77298",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = rp.random_index(5)\n",
    "\n",
    "print(\"Make sure all the labels in the photo match all the labels in the UVL scene!\")\n",
    "print(\"Its a good oppurtunity to double-check your annotations\")\n",
    "\n",
    "rp.display_image(\n",
    "    rp.vertically_concatenated_images(\n",
    "        rp.horizontally_concatenated_images(\n",
    "            rp.labeled_image(\n",
    "                rp.as_numpy_image(uvl_scenes[index]),\n",
    "                'Synthetic UVL Scene',\n",
    "                size=30,\n",
    "            ),\n",
    "            rp.labeled_image(\n",
    "                rp.as_numpy_image(colorized_scene_labels(uvl_labels,colors)[index]),\n",
    "                'Synthetic UVL Labels',\n",
    "                size=30,\n",
    "            ),\n",
    "        ),\n",
    "        rp.horizontally_concatenated_images(\n",
    "            rp.labeled_image(\n",
    "                rp.as_numpy_image(rgb[index]),\n",
    "                'Photo',\n",
    "                size=30,\n",
    "            ),\n",
    "            rp.labeled_image(\n",
    "                rp.as_numpy_image(colorized_scene_labels(labels,colors)[index]),\n",
    "                'Photo Labels',\n",
    "                size=30,\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
