{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credit to the original authors before I modified it: https://github.com/ndahlquist/pytorch-fourier-feature-networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "QDs4Im9WTQoy"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import rp\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "from IPython.display import clear_output\n",
    "import icecream\n",
    "from translator.pytorch_msssim import msssim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "5b645fbfa1884cddb45f74b0523f90bb",
      "b6733d1256364841bc5261e5230f6811",
      "9c615c4c38ba4e01a50a4ad8eeed28f8",
      "edc99973e53e4a8387b4f189a6651d60",
      "74b8d79aa3c14f4f9f52f4fc141925af",
      "f0f8712ad3c2447d8398da65a2327030",
      "11d82d2e895941f5a1a8cf2beb751204",
      "44a33ce72cea478ab64502cfb575f0dd"
     ]
    },
    "colab_type": "code",
    "id": "oSEJ3V2_GVrM",
    "outputId": "fbe96b83-0f54-4d89-971a-49f7a49925a2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from source.learnable_textures import LearnableImageFourier\n",
    "from source.learnable_textures import LearnableImageRaster \n",
    "from source.learnable_textures import LearnableImageMLP    \n",
    "from source.scene_reader       import extract_scene_uvs_and_scene_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Other Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Fourier Feature Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualize_features(number_of_features = 64):\n",
    "    #Keep number_of_features small to avoid displaying an image that's too big and laggy\n",
    "    \n",
    "    fourier_image=LearnableImageFourier(height=64, width=64)\n",
    "    \n",
    "    uv_features = fourier_image.uv_grid[0]\n",
    "    uv_features = rp.as_numpy_array(uv_features)\n",
    "    \n",
    "    print(\"Here are the two UV features used by the normal LearnableImageMLP (U and V on left and right, respectively):\")\n",
    "    icecream.ic(uv_features.shape, uv_features.min(), uv_features.max())\n",
    "    rp.display_image(rp.tiled_images(uv_features))\n",
    "    \n",
    "    features=fourier_image.features\n",
    "    features=fourier_image.get_features(torch.Tensor([.1,.2,.3,.4]))\n",
    "    \n",
    "    images=[]\n",
    "    for feature in features.squeeze(0):\n",
    "        image = rp.as_numpy_array(feature)\n",
    "        image = image + 1\n",
    "        image = image / 2\n",
    "        images.append(image)\n",
    "        \n",
    "    images = images[:number_of_features]\n",
    "        \n",
    "    print(\"Here's a sample of the %i fourier features used by LearnableImageFourier:\" % (2*fourier_image.num_features))\n",
    "    icecream.ic(features.shape, features.min(), features.max())\n",
    "    rp.display_image(rp.tiled_images(images))\n",
    "    \n",
    "visualize_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_scene_features():\n",
    "    uvl_map = rp.load_image('assets/mutant_alphadew_uvl_scene.exr')\n",
    "    uvl_map[:,:,2] = 0 #Get rid of the blue channel for visulization; in this demo it's just distracting\n",
    "    \n",
    "    scene_uvs, _ = extract_scene_uvs_and_scene_labels(rp.as_torch_images(uvl_map[None]), [0,127, 255])\n",
    "    assert len(scene_uvs.shape)==4 and scene_uvs.shape[0]==1 and scene_uvs.shape[1]==2\n",
    "\n",
    "    fourier_image = LearnableImageFourier()\n",
    "    feature_extractor = fourier_image.feature_extractor\n",
    "    scene_features = feature_extractor(scene_uvs)\n",
    "    scene_features = scene_features[0]\n",
    "    feature_maps = fourier_image.features[0]\n",
    "\n",
    "    # Convert range [-1, 1] to [0, 1] so we can display the full range\n",
    "    scene_features = (scene_features+1)/2 \n",
    "    feature_maps   = (feature_maps  +1)/2 \n",
    "\n",
    "    icecream.ic(uvl_map.shape, \n",
    "                scene_uvs.shape, \n",
    "                scene_features.shape, \n",
    "                feature_extractor.num_features, \n",
    "                fourier_image.features.shape,\n",
    "                feature_maps.shape)\n",
    "\n",
    "    print(\"A sample UVL scene:\")\n",
    "    rp.display_image(uvl_map)\n",
    "\n",
    "    print(\"A random fourier feature of that scene:\")\n",
    "\n",
    "    feature_index = rp.random_index(feature_maps)\n",
    "\n",
    "    rp.display_image(\n",
    "        rp.horizontally_concatenated_images(\n",
    "            rp.as_numpy_array(feature_maps  [feature_index]),\n",
    "            rp.as_numpy_array(scene_features[feature_index])\n",
    "        )\n",
    "    )\n",
    "    \n",
    "visualize_scene_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_features_sine_cos():\n",
    "    print(\"This cell shows how the first half of the features are sines, and the second half are cosines\")\n",
    "\n",
    "    num_features = 128\n",
    "    fourier_image = LearnableImageFourier(num_features=num_features)\n",
    "    feature_extractor = fourier_image.feature_extractor\n",
    "    feature_maps = fourier_image.features[0]\n",
    "\n",
    "    sines   = feature_maps[:num_features]\n",
    "    cosines = feature_maps[num_features:]\n",
    "\n",
    "    magnitudes = (sines**2 + cosines**2) ** .5\n",
    "\n",
    "    icecream.ic(\n",
    "        feature_extractor.num_features, \n",
    "        fourier_image.features.shape,\n",
    "        feature_maps.shape,\n",
    "        sines.shape,\n",
    "        cosines.shape,\n",
    "        magnitudes.shape,\n",
    "        sines.min(), sines.max(),\n",
    "        cosines.min(), cosines.max(),\n",
    "        magnitudes.min(), magnitudes.max(),\n",
    "    )\n",
    "\n",
    "\n",
    "    feature_index = rp.random_index(magnitudes)\n",
    "\n",
    "    sine      = (rp.as_numpy_array(sines     [feature_index]) + 1)/2\n",
    "    cosine    = (rp.as_numpy_array(cosines   [feature_index]) + 1)/2\n",
    "    magnitude = (rp.as_numpy_array(magnitudes[feature_index]) + 1)/2\n",
    "\n",
    "    print(\"Here's a random feature map's sine and cosine respectively:\")\n",
    "    rp.display_image(\n",
    "        rp.horizontally_concatenated_images(\n",
    "            rp.cv_text_to_image('sqrt('),\n",
    "            rp.labeled_image(sine,'(A sine feature)',position='bottom', size=20),\n",
    "            rp.cv_text_to_image('^2  +  '),\n",
    "            rp.labeled_image(cosine,'(its respective cosine)',position='bottom', size=20),\n",
    "            rp.cv_text_to_image('^2)  =  '),\n",
    "            rp.labeled_image(magnitude,'(magnitude = 1)',position='bottom', size=20),\n",
    "        )\n",
    "    )\n",
    "    \n",
    "visualize_features_sine_cos()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Running Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Target Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_image_choices={}\n",
    "\n",
    "target_image_choices['fox'      ] = 'https://live.staticflickr.com/7492/15677707699_d9d67acf9d_b.jpg'\n",
    "target_image_choices['magikarp' ] = 'https://static.pokemonpets.com/images/monsters-images-300-300/129-Magikarp.webp'\n",
    "target_image_choices['makeup'   ] = 'https://i.redd.it/vxvs3dgsbxw31.png'\n",
    "target_image_choices['snowflake'] = 'https://2s7gjr373w3x22jf92z99mgm5w-wpengine.netdna-ssl.com/wp-content/uploads/2020/11/snowflake_shutterstock_kichigin.jpg'\n",
    "target_image_choices['portal'   ] = 'https://static.wikia.nocookie.net/half-life/images/9/9d/Atlas_P-body_fhp2.jpg/revision/latest?cb=20110519013122&path-prefix=en'\n",
    "target_image_choices['uv'       ] = 'https://i.imgur.com/w9Mc6qN.png'\n",
    "\n",
    "def display_target_images():\n",
    "    target_labels, target_images = zip(*target_image_choices.items())\n",
    "    target_images = [rp.load_image(image) for image in target_images]\n",
    "    target_images = [rp.cv_resize_image(image,(128,128)) for image in target_images]\n",
    "    target_images = rp.labeled_images(target_images, target_labels)\n",
    "    target_images = rp.tiled_images(target_images)\n",
    "    target_images = rp.labeled_image(target_images, \"Choices\", size=30)\n",
    "    rp.display_image(target_images)\n",
    "\n",
    "def load_target_image(target_image:str):\n",
    "    target_image = rp.load_image    (target_image, use_cache=True)\n",
    "    target_image = rp.as_float_image(target_image)\n",
    "    target_image = rp.as_rgb_image  (target_image)\n",
    "    target_image = rp.crop_image    (target_image, target_height, target_width, origin='center')\n",
    "    target_image = target_image.copy()\n",
    "    return target_image\n",
    "\n",
    "display_target_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_height = target_width = 512\n",
    "target_image = target_image_choices['portal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_image = load_target_image(target_image)\n",
    "\n",
    "assert rp.get_image_height(target_image) == target_height\n",
    "assert rp.get_image_width (target_image) == target_width \n",
    "\n",
    "print(\"Target Image:\")\n",
    "icecream.ic(target_image.shape, target_image.dtype, type(target_image), target_image.max(), target_image.min())\n",
    "rp.display_image(target_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Testing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "5b645fbfa1884cddb45f74b0523f90bb",
      "b6733d1256364841bc5261e5230f6811",
      "9c615c4c38ba4e01a50a4ad8eeed28f8",
      "edc99973e53e4a8387b4f189a6651d60",
      "74b8d79aa3c14f4f9f52f4fc141925af",
      "f0f8712ad3c2447d8398da65a2327030",
      "11d82d2e895941f5a1a8cf2beb751204",
      "44a33ce72cea478ab64502cfb575f0dd"
     ]
    },
    "colab_type": "code",
    "id": "oSEJ3V2_GVrM",
    "outputId": "fbe96b83-0f54-4d89-971a-49f7a49925a2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_test(method         = 'fourier',\n",
    "             criterion      = 'mse'    ,\n",
    "             num_features   = 128      ,\n",
    "             hidden_dim     = 256      ,\n",
    "             scale          = 10       ,\n",
    "             iter_per_epoch = 100      ,\n",
    "             learning_rate  = 1e-4     ,\n",
    "             num_epochs     = 4        ,\n",
    "             save_path      = None     ,\n",
    "             load_path      = None     ):\n",
    "    \n",
    "    print('Method:',method)\n",
    "    \n",
    "    assert method                 in     'fourier mlp raster'.split()\n",
    "    assert set(criterion.split()) <= set('mse msssim l1'.split())\n",
    "\n",
    "    target = rp.as_torch_image(target_image).to(device)\n",
    "    \n",
    "    print('Target:')\n",
    "    rp.display_image(rp.as_numpy_image(target))\n",
    "    \n",
    "    \n",
    "    if method=='mlp':\n",
    "        learnable_image=LearnableImageMLP(target_height,\n",
    "                                          target_width,\n",
    "                                          hidden_dim=hidden_dim)\n",
    "    elif method=='fourier':\n",
    "        learnable_image=LearnableImageFourier(target_height,\n",
    "                                              target_width,\n",
    "                                              num_features=num_features,\n",
    "                                              hidden_dim=hidden_dim,\n",
    "                                              scale=scale)\n",
    "    elif method=='raster':\n",
    "        learnable_image=LearnableImageRaster(target_height,\n",
    "                                             target_width)\n",
    "        \n",
    "    learnable_image.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(learnable_image.parameters(), lr=learning_rate)\n",
    "    \n",
    "    images = []\n",
    "    losses = []\n",
    "\n",
    "    def display_current_image():\n",
    "        image = learnable_image.as_numpy_image()\n",
    "        images.append(image)\n",
    "        rp.display_image(image)\n",
    "        return image\n",
    "    \n",
    "    if load_path:\n",
    "        if rp.file_exists(load_path):\n",
    "            state = torch.load(load_path)\n",
    "            learnable_image.load_state_dict(state)\n",
    "\n",
    "            print(\"Loaded state:\")\n",
    "            display_current_image()\n",
    "            \n",
    "        else:\n",
    "            print(load_path, 'does not exist and cannot be loaded. Weights will be randomly initialized.')\n",
    "    \n",
    "    throw_error=False\n",
    "    \n",
    "    try:\n",
    "        for iteration in tqdm(range(num_epochs*iter_per_epoch)):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            generated = learnable_image()\n",
    "\n",
    "            loss = 0\n",
    "            if 'msssim' in criterion:\n",
    "                loss += -msssim(target[None],generated[None],normalize=True)\n",
    "                loss += 1 #Make the min loss 0, so we can do log plots of losses\n",
    "            if 'mse'    in criterion:\n",
    "                loss += torch.nn.functional.l1_loss(target, generated)\n",
    "            if 'l1'     in criterion:\n",
    "                loss += (generated-target).abs().mean()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            losses.append(float(loss))\n",
    "\n",
    "            if iteration % iter_per_epoch == 0:\n",
    "                epoch = iteration // iter_per_epoch\n",
    "                print('Epoch %d, loss = %.03f' % (epoch, float(loss)))\n",
    "                image=display_current_image()\n",
    "                \n",
    "        images.append(image)\n",
    "    except KeyboardInterrupt:\n",
    "        throw_error=True\n",
    "            \n",
    "    clear_output()\n",
    "    icecream.ic(method, criterion, num_features, hidden_dim, scale, iter_per_epoch, learning_rate, num_epochs)\n",
    "    rp.line_graph_via_bokeh(losses,xlabel='Iter',ylabel='Loss',title=method,logy=10)\n",
    "    rp.display_image_slideshow(images)\n",
    "    \n",
    "    if save_path:\n",
    "        state=learnable_image.state_dict()\n",
    "        torch.save(state,save_path)\n",
    "        print(\"Saving\",save_path)\n",
    "    \n",
    "    if throw_error:\n",
    "        raise KeyboardInterrupt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#This cell tests the loading and saving capabilities\n",
    "%mkdir untracked\n",
    "run_test('fourier', 'msssim', \n",
    "         num_features=128, hidden_dim=256, scale=100, iter_per_epoch=100, num_epochs=3, learning_rate=1e-4,\n",
    "         load_path='untracked/r.pt', save_path='untracked/r.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_test('fourier', 'msssim', \n",
    "         num_features=128, hidden_dim=20, scale=20, iter_per_epoch=100, num_epochs=30, learning_rate=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_test('fourier', 'msssim', \n",
    "         num_features=128, hidden_dim=256, scale=10, iter_per_epoch=100, num_epochs=30, learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_test('fourier', 'mse', num_features=128, hidden_dim=256, scale=1, iter_per_epoch=100, num_epochs=30, learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_test('fourier', 'mse msssim', num_features=200, hidden_dim=256, scale=10, iter_per_epoch=100, num_epochs=30, learning_rate=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_test('fourier', 'mse msssim', \n",
    "         num_features=128, hidden_dim=256, scale=1, iter_per_epoch=100, num_epochs=30, learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_test('raster','mse',iter_per_epoch=1000,num_epochs=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_test('raster','msssim mse',iter_per_epoch=1000,num_epochs=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_test('raster','msssim',iter_per_epoch=1000,num_epochs=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_test('raster','l1',iter_per_epoch=1000,num_epochs=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_test('raster','l1 mse',iter_per_epoch=1000,num_epochs=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test('raster','mse',iter_per_epoch=1000,num_epochs=3, learning_rate=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test('mlp','msssim',hidden_dim=1024,iter_per_epoch=100,num_epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test('mlp',hidden_dim=1024,iter_per_epoch=100,num_epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test('mlp','msssim mse',hidden_dim=1024,iter_per_epoch=100,num_epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test('mlp',hidden_dim=256,iter_per_epoch=100,num_epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test('mlp',num_features=128,hidden_dim=256,scale=1,iter_per_epoch=100,num_epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test('fourier',num_features=128,hidden_dim=256,scale=1,iter_per_epoch=100,num_epochs=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test('fourier',num_features=2,hidden_dim=128,scale=1,iter_per_epoch=100,num_epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test('fourier',num_features=256,hidden_dim=5,scale=1,iter_per_epoch=2000,num_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_test('fourier',num_features=256,hidden_dim=256,scale=1,iter_per_epoch=100,num_epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Multi-Image Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_multi_image_test(method         = 'fourier',\n",
    "                         criterion      = 'mse'    ,\n",
    "                         image_names    = 'portal makeup fox magikarp uv snowflake',\n",
    "                         num_features   = 128      ,\n",
    "                         hidden_dim     = 256      ,\n",
    "                         scale          = 10       ,\n",
    "                         iter_per_epoch = 100      ,\n",
    "                         learning_rate  = 1e-4     ,\n",
    "                         num_epochs     = 4        ,\n",
    "                         save_path      = None     ,\n",
    "                         load_path      = None     ):\n",
    "    \n",
    "    print('Method:',method)\n",
    "    \n",
    "    assert method in 'fourier mlp raster'.split()\n",
    "    assert set(criterion.split()) <= set('mse msssim l1'.split())\n",
    "\n",
    "    image_names = image_names.split()\n",
    "    num_images = len(image_names)\n",
    "    images = [load_target_image(target_image_choices[image_name]) for image_name in image_names]\n",
    "    target_image = np.concatenate(images, axis=2) #Concatenate all images into channels\n",
    "    \n",
    "    target = rp.as_torch_image(target_image).to(device)\n",
    "    icecream.ic(num_images, target.shape)\n",
    "    \n",
    "    if method=='mlp':\n",
    "        learnable_image=LearnableImageMLP(target_height,\n",
    "                                          target_width,\n",
    "                                          hidden_dim=hidden_dim,\n",
    "                                          num_channels=num_images*3)\n",
    "    elif method=='fourier':\n",
    "        learnable_image=LearnableImageFourier(target_height,\n",
    "                                              target_width,\n",
    "                                              num_features=num_features,\n",
    "                                              hidden_dim=hidden_dim,\n",
    "                                              scale=scale,\n",
    "                                              num_channels=num_images*3)\n",
    "    elif method=='raster':\n",
    "        learnable_image=LearnableImageRaster(target_height,\n",
    "                                             target_width,\n",
    "                                             num_channels=num_images*3)\n",
    "        \n",
    "    learnable_image.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(learnable_image.parameters(), lr=learning_rate)\n",
    "    \n",
    "    output_images = []\n",
    "    losses = []\n",
    "            \n",
    "    def get_current_multi_image():\n",
    "        #Our learnable_image has 3*num_images channels\n",
    "        #This function takes learnable_image() and returns an image as defined by rp.is_image,\n",
    "        #that displays all of those images at once.\n",
    "            \n",
    "        multi_image = rp.as_numpy_image(learnable_image())\n",
    "            \n",
    "        tiles = []\n",
    "        for i in range(num_images):\n",
    "            tiles.append(multi_image[:,:,i*3:i*3+3])\n",
    "        \n",
    "        output = rp.tiled_images(tiles)\n",
    "            \n",
    "        assert rp.is_image(output)\n",
    "        return output\n",
    "            \n",
    "    def display_current_image():\n",
    "        image = get_current_multi_image()\n",
    "        output_images.append(image)\n",
    "        rp.display_image(image)\n",
    "        return image\n",
    "    \n",
    "    if load_path:\n",
    "        if rp.file_exists(load_path):\n",
    "            state = torch.load(load_path)\n",
    "            learnable_image.load_state_dict(state)\n",
    "\n",
    "            print(\"Loaded state:\")\n",
    "            display_current_image()\n",
    "            \n",
    "        else:\n",
    "            print(load_path, 'does not exist and cannot be loaded. Weights will be randomly initialized.')\n",
    "    \n",
    "    throw_error = False\n",
    "    \n",
    "    try:\n",
    "        for iteration in tqdm(range(num_epochs*iter_per_epoch)):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            generated = learnable_image()\n",
    "\n",
    "            loss = 0\n",
    "            if 'msssim' in criterion:\n",
    "                loss += -msssim(target[None],generated[None],normalize=True)\n",
    "                loss += 1 #Make the min loss 0, so we can do log plots of losses\n",
    "            if 'mse'    in criterion:\n",
    "                loss += torch.nn.functional.l1_loss(target, generated)\n",
    "            if 'l1'     in criterion:\n",
    "                loss += (generated-target).abs().mean()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            losses.append(float(loss))\n",
    "\n",
    "            if iteration % iter_per_epoch == 0:\n",
    "                epoch = iteration // iter_per_epoch\n",
    "                print('Epoch %d, loss = %.03f' % (epoch, float(loss)))\n",
    "                image=display_current_image()\n",
    "                \n",
    "        output_images.append(image)\n",
    "    except KeyboardInterrupt:\n",
    "        throw_error = True #Don't continue to other cells after this one\n",
    "        pass\n",
    "            \n",
    "    clear_output()\n",
    "    icecream.ic(method, criterion, num_features, hidden_dim, scale, iter_per_epoch, learning_rate, num_epochs)\n",
    "    rp.line_graph_via_bokeh(losses,xlabel='Iter',ylabel='Loss',logy=10,\n",
    "                  title='multi '+method+' '+criterion+'\\n'+' '.join(image_names))\n",
    "    rp.display_image_slideshow(output_images)\n",
    "    \n",
    "    if save_path:\n",
    "        state=learnable_image.state_dict()\n",
    "        torch.save(state,save_path)\n",
    "        print(\"Saving\",save_path)\n",
    "        \n",
    "    if throw_error:\n",
    "        raise KeyboardInterrupt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_multi_image_test('fourier','mse msssim',\n",
    "                    num_features=256,hidden_dim=256,scale=10,iter_per_epoch=100,num_epochs=20,learning_rate=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_multi_image_test('fourier','mse msssim',\n",
    "                    num_features=128,hidden_dim=128,scale=10,iter_per_epoch=100,num_epochs=16,learning_rate=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_multi_image_test('fourier','mse msssim',\n",
    "                    num_features=128,hidden_dim=128,scale=10,iter_per_epoch=1000,num_epochs=16,learning_rate=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_multi_image_test('fourier','mse msssim',\n",
    "                    num_features=128,hidden_dim=128,scale=10,iter_per_epoch=1000,num_epochs=16,learning_rate=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_multi_image_test('fourier','mse msssim',\n",
    "                    num_features=256,hidden_dim=256,scale=20,iter_per_epoch=1000,num_epochs=16,learning_rate=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_multi_image_test('fourier','mse msssim',\n",
    "                    num_features=64,hidden_dim=128,scale=10,iter_per_epoch=100,num_epochs=3,learning_rate=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Conditional-Image Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_condi_image_test(method         = 'fourier',\n",
    "                         criterion      = 'mse'    ,\n",
    "                         image_names    = 'portal makeup fox magikarp uv snowflake',\n",
    "                         num_features   = 128      ,\n",
    "                         hidden_dim     = 256      ,\n",
    "                         scale          = 10       ,\n",
    "                         iter_per_epoch = 100      ,\n",
    "                         learning_rate  = 1e-4     ,\n",
    "                         num_epochs     = 4        ,\n",
    "                         save_path      = None     ,\n",
    "                         load_path      = None     ):\n",
    "    \n",
    "    print('Method:',method)\n",
    "    \n",
    "    assert method in 'fourier mlp'.split()\n",
    "    assert set(criterion.split()) <= set('mse msssim l1'.split())\n",
    "\n",
    "    image_names = image_names.split()\n",
    "    num_images = len(image_names)\n",
    "    images = [load_target_image(target_image_choices[image_name]) for image_name in image_names]\n",
    "    target_image = np.concatenate(images, axis=2) #Concatenate all images into channels\n",
    "    \n",
    "    target = rp.as_torch_image(target_image).to(device)\n",
    "    icecream.ic(num_images, target.shape)\n",
    "    \n",
    "    if method=='mlp':\n",
    "        assert False, 'Not yet implemented in learnable_textures.py'\n",
    "        learnable_image=LearnableImageMLP(target_height,\n",
    "                                          target_width,\n",
    "                                          hidden_dim=hidden_dim,\n",
    "                                          num_channels=3)\n",
    "    elif method=='fourier':\n",
    "        learnable_image=LearnableImageFourier(target_height,\n",
    "                                              target_width,\n",
    "                                              num_features=num_features,\n",
    "                                              hidden_dim=hidden_dim,\n",
    "                                              scale=scale,\n",
    "                                              num_channels=3)\n",
    "        \n",
    "    learnable_image.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(learnable_image.parameters(), lr=learning_rate)\n",
    "    \n",
    "    output_images = []\n",
    "    losses = []\n",
    "    \n",
    "    def get_learnable_images():\n",
    "        images = []\n",
    "        for i in range(num_images):\n",
    "            condition = torch.zeros(num_images).to(device)\n",
    "            condition[i]=1\n",
    "            image = learnable_image(condition=condition)\n",
    "            images.append(image)\n",
    "        return torch.cat(images)\n",
    "            \n",
    "    def get_current_multi_image():\n",
    "        #Our learnable_image has 3*num_images channels\n",
    "        #This function takes learnable_image() and returns an image as defined by rp.is_image,\n",
    "        #that displays all of those images at once.\n",
    "            \n",
    "        multi_image = rp.as_numpy_image(get_learnable_images())\n",
    "            \n",
    "        tiles = []\n",
    "        for i in range(num_images):\n",
    "            tiles.append(multi_image[:,:,i*3:i*3+3])\n",
    "        \n",
    "        output = rp.tiled_images(tiles)\n",
    "            \n",
    "        assert rp.is_image(output)\n",
    "        return output\n",
    "            \n",
    "    def display_current_image():\n",
    "        image = get_current_multi_image()\n",
    "        output_images.append(image)\n",
    "        rp.display_image(image)\n",
    "        return image\n",
    "    \n",
    "    if load_path:\n",
    "        if rp.file_exists(load_path):\n",
    "            state = torch.load(load_path)\n",
    "            learnable_image.load_state_dict(state)\n",
    "\n",
    "            print(\"Loaded state:\")\n",
    "            display_current_image()\n",
    "            \n",
    "        else:\n",
    "            print(load_path, 'does not exist and cannot be loaded. Weights will be randomly initialized.')\n",
    "    \n",
    "    throw_error = False\n",
    "    \n",
    "    try:\n",
    "        for iteration in tqdm(range(num_epochs*iter_per_epoch)):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            generated = get_learnable_images()\n",
    "\n",
    "            loss = 0\n",
    "            if 'msssim' in criterion:\n",
    "                loss += -msssim(target[None],generated[None],normalize=True)\n",
    "                loss += 1 #Make the min loss 0, so we can do log plots of losses\n",
    "            if 'mse'    in criterion:\n",
    "                loss += torch.nn.functional.l1_loss(target, generated)\n",
    "            if 'l1'     in criterion:\n",
    "                loss += (generated-target).abs().mean()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            losses.append(float(loss))\n",
    "\n",
    "            if iteration % iter_per_epoch == 0:\n",
    "                epoch = iteration // iter_per_epoch\n",
    "                print('Epoch %d, loss = %.03f' % (epoch, float(loss)))\n",
    "                image=display_current_image()\n",
    "                \n",
    "        output_images.append(image)\n",
    "    except KeyboardInterrupt:\n",
    "        throw_error = True #Don't continue to other cells after this one\n",
    "        pass\n",
    "            \n",
    "    clear_output()\n",
    "    icecream.ic(method, criterion, num_features, hidden_dim, scale, iter_per_epoch, learning_rate, num_epochs)\n",
    "    rp.line_graph_via_bokeh(losses,xlabel='Iter',ylabel='Loss',logy=10,\n",
    "                  title='cond '+method+' '+criterion+'\\n'+' '.join(image_names))\n",
    "    rp.display_image_slideshow(output_images)\n",
    "    \n",
    "    if save_path:\n",
    "        state=learnable_image.state_dict()\n",
    "        torch.save(state,save_path)\n",
    "        print(\"Saving\",save_path)\n",
    "        \n",
    "    if throw_error:\n",
    "        raise KeyboardInterrupt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_condi_image_test('fourier','mse msssim',\n",
    "                    num_features=256,hidden_dim=256,scale=10,iter_per_epoch=100,num_epochs=16,learning_rate=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_condi_image_test('fourier','mse msssim',\n",
    "                    num_features=128,hidden_dim=128,scale=10,iter_per_epoch=1000,num_epochs=16,learning_rate=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_condi_image_test('fourier','mse msssim',\n",
    "                    num_features=128,hidden_dim=128,scale=10,iter_per_epoch=1000,num_epochs=16,learning_rate=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_condi_image_test('fourier','mse msssim',\n",
    "                    num_features=128,hidden_dim=128,scale=10,iter_per_epoch=100,num_epochs=16,learning_rate=1e-2)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOKScyN4MJQ24MK/kpRd05x",
   "collapsed_sections": [
    "gS5okm9Laeeh"
   ],
   "include_colab_link": true,
   "name": "demo.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-showcode": true,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "11d82d2e895941f5a1a8cf2beb751204": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1aa68f3edcbe44faa79b39d3c5aa67b4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2c18b120fb344e0c9c5c90d8b44de193": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "44a33ce72cea478ab64502cfb575f0dd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4a25269152284f1ca7e97e85a56be79a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b645fbfa1884cddb45f74b0523f90bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9c615c4c38ba4e01a50a4ad8eeed28f8",
       "IPY_MODEL_edc99973e53e4a8387b4f189a6651d60"
      ],
      "layout": "IPY_MODEL_b6733d1256364841bc5261e5230f6811"
     }
    },
    "63ec17553916465b8b4c2adf7b0e53f4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "74b8d79aa3c14f4f9f52f4fc141925af": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "84eb7a39163d4b79ac84804696a08cf2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_aeeccd61355149c396e4335f36d9db1b",
       "IPY_MODEL_d4bf1905ae294d2db30285111efaea90"
      ],
      "layout": "IPY_MODEL_63ec17553916465b8b4c2adf7b0e53f4"
     }
    },
    "86c18dab94fc431c90ff3cb297c8b6bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "9c615c4c38ba4e01a50a4ad8eeed28f8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f0f8712ad3c2447d8398da65a2327030",
      "max": 400,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_74b8d79aa3c14f4f9f52f4fc141925af",
      "value": 400
     }
    },
    "aeeccd61355149c396e4335f36d9db1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4a25269152284f1ca7e97e85a56be79a",
      "max": 400,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_86c18dab94fc431c90ff3cb297c8b6bb",
      "value": 400
     }
    },
    "b6733d1256364841bc5261e5230f6811": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d4bf1905ae294d2db30285111efaea90": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1aa68f3edcbe44faa79b39d3c5aa67b4",
      "placeholder": "​",
      "style": "IPY_MODEL_2c18b120fb344e0c9c5c90d8b44de193",
      "value": " 400/400 [00:56&lt;00:00,  7.03it/s]"
     }
    },
    "edc99973e53e4a8387b4f189a6651d60": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_44a33ce72cea478ab64502cfb575f0dd",
      "placeholder": "​",
      "style": "IPY_MODEL_11d82d2e895941f5a1a8cf2beb751204",
      "value": " 400/400 [01:03&lt;00:00,  6.26it/s]"
     }
    },
    "f0f8712ad3c2447d8398da65a2327030": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
